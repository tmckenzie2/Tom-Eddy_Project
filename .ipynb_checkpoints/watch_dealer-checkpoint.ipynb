{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watch Dealer\n",
    "### Programmers: Tom McKenzie, Eddy Nassif\n",
    "### Class: Data Mining, Spring 2019\n",
    "### Final Project\n",
    "\n",
    "\n",
    "\n",
    "# Getting Started\n",
    "Our project aims to help consumers find the best deals on a given product based on previous price history and it’s trend for the past 90 days. We will be focusing on Rolex wristwatches, and will be using a variety of classification methods to help forecast pricing and ultimately decide whether or not the price for a current listing is a good or bad deal. The dataset will be created by using Ebay’s API to get data on previously sold listings. \n",
    "\n",
    "## The Data\n",
    "We will be acquiring our data using Ebay's API. This API is easy to use and makes grabbing previous sales easy! However, no dataset is perfect, and we had to go through hefty pre-processing to get the data reaedy. There were three steps to our data collection: Gathering, Cleaning, and Classifying.\n",
    "\n",
    "#### Gathering the data:\n",
    "Like we said earlier, data gathering was completed using Ebay's API. [Here](https://developer.ebay.com/docs) is a link to the documentation if you want to investigate further.\n",
    "\n",
    "\n",
    "Below is the function we used to send a response to Ebay's API. As you can see, we pass in some keywords, sort the results from newest to oldest, ask for 100 entries per page, give it a page number, and a minimum and maximum price for previously sold listings. We use minimum and maximum price as a screen for watch parts and accessories. By setting a mininum price at a level that no Rolex will go under, we save a lot of time in cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(Keywords, pageNum, minPrice, maxPrice, api):\n",
    "    response = api.execute('findCompletedItems', {\n",
    "        'keywords': Keywords,\n",
    "        'sortOrder': 'EndTimeLatest',\n",
    "        'paginationInput': {'entriesPerPage': '100',\n",
    "                            'pageNumber': pageNum},\n",
    "        'itemFilter': [\n",
    "            # {'name': 'Condition', 'value': condition},\n",
    "            {'name': 'SoldItemsOnly', 'value': True},\n",
    "            {'name': 'MinPrice', 'value': minPrice},\n",
    "            {'name': 'MaxPrice', 'value': maxPrice}\n",
    "        ]\n",
    "    }\n",
    "                           )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with any API, you need an API Key. We are sharing an API key, and we will be including ours as a means of demonstration. If you would like to try this project for yourself, please register for your own API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebaysdk.finding import Connection as finding\n",
    "api = finding(appid='EddyNass-Scraper-PRD-651ca6568-7ae32d61', config_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have set the parameters for the API, we can send a request! Let's gather all the items on the first four pages, 400 items in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<item><itemid>254217635900</itemid><title>2005 Unique Rolex Explorer 114270 Black PVD / DLC</title><globalid>EBAY-US</globalid><primarycategory><categoryid>31387</categoryid><categoryname>Wristwatches</categoryname></primarycategory><galleryurl>http://thumbs1.ebaystatic.com/m/mpdOrwj6IVbG2M_ae6sI2cg/140.jpg</galleryurl><viewitemurl>http://www.ebay.com/itm/2005-Unique-Rolex-Explorer-114270-Black-PVD-DLC-/254217635900</viewitemurl><paymentmethod>PayPal</paymentmethod><autopay>false</autopay><postalcode>33132</postalcode><location>Miami,FL,USA</location><country>US</country><shippinginfo><shippingservicecost currencyid=\"USD\">65.0</shippingservicecost><shippingtype>Flat</shippingtype><shiptolocations>Worldwide</shiptolocations><expeditedshipping>true</expeditedshipping><onedayshippingavailable>false</onedayshippingavailable><handlingtime>2</handlingtime></shippinginfo><sellingstatus><currentprice currencyid=\"USD\">4050.0</currentprice><convertedcurrentprice currencyid=\"USD\">4050.0</convertedcurrentprice><bidcount>27</bidcount><sellingstate>EndedWithSales</sellingstate></sellingstatus><listinginfo><bestofferenabled>false</bestofferenabled><buyitnowavailable>false</buyitnowavailable><starttime>2019-05-02T09:53:30.000Z</starttime><endtime>2019-05-09T00:40:02.000Z</endtime><listingtype>Auction</listingtype><gift>false</gift><watchcount>95</watchcount></listinginfo><returnsaccepted>false</returnsaccepted><condition><conditionid>3000</conditionid><conditiondisplayname>Pre-owned</conditiondisplayname></condition><ismultivariationlisting>false</ismultivariationlisting><topratedlisting>false</topratedlisting></item>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "Keywords = \"Rolex Wristwatch\"\n",
    "minPrice = 3000\n",
    "maxPrice = 12000\n",
    "pageNum = 1\n",
    "# Collect all items from ebay on page1 through 4\n",
    "while pageNum <= 4:\n",
    "    soup = BeautifulSoup(response(Keywords, pageNum, minPrice, maxPrice, api).content, 'lxml')\n",
    "    if pageNum == 1:\n",
    "        items = soup.find_all('item')\n",
    "    else:\n",
    "        items += soup.find_all('item')\n",
    "    pageNum += 1\n",
    "items[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ew! The result doesn't look too pretty! We even had to shorten it significantly so it didn't take up the whole notebook! What's happening here is that \"items\" is collecting all of the information that Ebay is sending us, but we can parse it out using BeautifulSoup. To keep only the necessary attributes, we wrote a function called get_attribtues. Note: Collecting this data takes a long time to run, about 15 minutes. Since it takes so long to run, we will only be using the first few lines in the Jupyter Notebook, but our project comes with an already compiled data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes(items, index, df):\n",
    "    for item in items[:3]:\n",
    "        price = int(round(float(item.currentprice.string)))\n",
    "        dateSold = item.endtime.string\n",
    "        dt = parse(dateSold)\n",
    "        date = dt.date()\n",
    "        url = item.viewitemurl.string.lower()\n",
    "        cond = item.conditiondisplayname.string.lower()\n",
    "        listingType = item.listingtype.string\n",
    "        start = item.starttime.string\n",
    "        dt = parse(start)\n",
    "        start = dt.date()\n",
    "\n",
    "        # movement, brand, case material, and band material attributes for each item\n",
    "        # if the attributes are left out of the e-bay pages ITEM SPECIFICS then they\n",
    "        # will be returned as NULL\n",
    "\n",
    "        MPN = get_details(get_page(url), \"MPN:\")\n",
    "        movement = get_details(get_page(url), \"Movement:\")\n",
    "        model = get_details(get_page(url), \"Model:\")\n",
    "        case_material = get_details(get_page(url), \"Case Material:\")\n",
    "        band_material = get_details(get_page(url), \"Band Material:\")\n",
    "\n",
    "        try:\n",
    "            shipping = int(round(float(item.shippingservicecost.string)))\n",
    "            total = price + shipping\n",
    "        except:\n",
    "            total = price\n",
    "\n",
    "        # push data to df\n",
    "        df.loc[index] = [date, total, price, cond, MPN, movement, case_material, band_material, model, listingType,\n",
    "                         start, url]\n",
    "        index += 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_attributes uses get_details, which is used to search the item description and extract attributes such as model, case material, etc. These are attributes we could not extract with the api alone. Get_details also calls get_page, which requests the URL and makes it ready to parse the html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    response = requests.get(url, headers={'Connection': 'close'})\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    return soup\n",
    "\n",
    "\n",
    "def get_details(url, att_name):\n",
    "    att_description = \"NULL\"\n",
    "    data = []\n",
    "    table = url.find(attrs={'class': 'section'})\n",
    "    if table is not None:\n",
    "        rows = table.findAll('tr')\n",
    "        for row in rows:\n",
    "            cols = row.findAll('td')\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            data.append([ele for ele in cols if ele])\n",
    "    for i in data:\n",
    "        if i[:1] == [att_name]:\n",
    "            att_description = i[1]\n",
    "        elif i[2:3] == [att_name]:\n",
    "            att_description = i[3]\n",
    "\n",
    "    return att_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run our items through get_attributes, the results are much more neat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total</th>\n",
       "      <th>price</th>\n",
       "      <th>condition</th>\n",
       "      <th>MPN</th>\n",
       "      <th>movement</th>\n",
       "      <th>case material</th>\n",
       "      <th>band material</th>\n",
       "      <th>model</th>\n",
       "      <th>listingType</th>\n",
       "      <th>start</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>4115.0</td>\n",
       "      <td>4050.0</td>\n",
       "      <td>pre-owned</td>\n",
       "      <td>114270</td>\n",
       "      <td>Mechanical (Automatic)</td>\n",
       "      <td>Stainless Steel</td>\n",
       "      <td>Stainless Steel</td>\n",
       "      <td>Rolex Explorer</td>\n",
       "      <td>Auction</td>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>http://www.ebay.com/itm/2005-unique-rolex-expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>5965.0</td>\n",
       "      <td>5900.0</td>\n",
       "      <td>pre-owned</td>\n",
       "      <td>16233</td>\n",
       "      <td>Mechanical (Automatic)</td>\n",
       "      <td>Stainless Steel &amp; 18K Gold</td>\n",
       "      <td>Stainless Steel &amp; 18K Gold</td>\n",
       "      <td>Datejust</td>\n",
       "      <td>Auction</td>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>http://www.ebay.com/itm/2001-rolex-16238-datej...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>pre-owned</td>\n",
       "      <td>Does Not Apply</td>\n",
       "      <td>Swiss Automatic</td>\n",
       "      <td>Stainless Steel</td>\n",
       "      <td>Stainless Steel</td>\n",
       "      <td>Submariner</td>\n",
       "      <td>FixedPrice</td>\n",
       "      <td>2019-04-11</td>\n",
       "      <td>http://www.ebay.com/itm/rolex-submariner-16610...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   total   price  condition             MPN  \\\n",
       "0  2019-05-09  4115.0  4050.0  pre-owned          114270   \n",
       "1  2019-05-09  5965.0  5900.0  pre-owned           16233   \n",
       "2  2019-05-09  7600.0  7600.0  pre-owned  Does Not Apply   \n",
       "\n",
       "                 movement               case material  \\\n",
       "0  Mechanical (Automatic)             Stainless Steel   \n",
       "1  Mechanical (Automatic)  Stainless Steel & 18K Gold   \n",
       "2         Swiss Automatic             Stainless Steel   \n",
       "\n",
       "                band material           model listingType       start  \\\n",
       "0             Stainless Steel  Rolex Explorer     Auction  2019-05-02   \n",
       "1  Stainless Steel & 18K Gold        Datejust     Auction  2019-05-02   \n",
       "2             Stainless Steel      Submariner  FixedPrice  2019-04-11   \n",
       "\n",
       "                                                 url  \n",
       "0  http://www.ebay.com/itm/2005-unique-rolex-expl...  \n",
       "1  http://www.ebay.com/itm/2001-rolex-16238-datej...  \n",
       "2  http://www.ebay.com/itm/rolex-submariner-16610...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "\n",
    "index = 0\n",
    "# Declare data frame\n",
    "df = pd.DataFrame(columns=('date', 'total', 'price', 'condition', 'MPN', 'movement', 'case material',\n",
    "                           'band material', 'model', 'listingType', 'start', 'url'), dtype=float)\n",
    "\n",
    "df = get_attributes(items, index, df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this data looks a lot better! This is the basic method we used for gathering our data. Next, we had to clean the data.\n",
    "\n",
    "### Cleaning the Data\n",
    "The main issue with our data was the model number. To classify the data appropriately, we needed consistent model names throughout the dataset. Unfortunately, this doesn't look so pretty. We needed to account for every possible misspelling or variation for each name, and correct it. This process needed to be repeated for the model name, band material, and watch movement. Common mistakes would be just saying \"plat\" instead of platinum for the band material, or Datejust 2 instead of Datejust II. \n",
    "\n",
    "To tackle this issue, we changed all words to lowercase using casefold(), then used if else statements to correct and check for incorrect values. Example code looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_case_material(case_col):\n",
    "    clean_case_col = []\n",
    "    for i in case_col:\n",
    "        if \"plati\".casefold() in i.casefold():\n",
    "            clean_case_col.append('Platinum')\n",
    "        elif \"14\".casefold() in i.casefold():\n",
    "            clean_case_col.append('14k Gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran a variation of the above code for every possible model, movement, and band material we could find. After the attributes were normalized, we were able to join the cleaned dataset with our market value dataset and be classified.\n",
    "\n",
    "### Classifying the Data\n",
    "When you purchase something, the person selling you the item won't tell you if you are getting a good or bad deal. It is up to the customer to decide. However, when we are trying to build a classifier for watch valuation, we need to agree on what is a good and bad deal. To set market values, we used [Bob's Watches](https://www.bobswatches.com/used-rolex-prices) as a baseline for whether or not the ebay sale was a good or bad deal. \n",
    "\n",
    "After downloading the Bob's Watches dataset, we were able to use that dataset with our cleaned ebay dataset and classify each listing as a good or bad deal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_deal():\n",
    "    table = u.read_csv('rolex_prices_data.csv')\n",
    "\n",
    "    price_col = u.get_column(table,1)\n",
    "\n",
    "    clean_prices = []\n",
    "    for price in price_col:\n",
    "        price = price.replace(',', '')\n",
    "        price = price.replace('$', '')\n",
    "        \n",
    "        clean_prices.append(price)\n",
    "\n",
    "    clean_table = []\n",
    "    count = 0\n",
    "    for row in table:\n",
    "        clean_table.append([row[0], clean_prices[count]])\n",
    "        count = count + 1\n",
    "\n",
    "    u.write_to_file(clean_table, 'rolex_prices_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
