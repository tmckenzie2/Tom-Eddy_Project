{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watch Dealer\n",
    "### Programmers: Tom McKenzie, Eddy Nassif\n",
    "### Class: Data Mining, Spring 2019\n",
    "### Final Project\n",
    "\n",
    "\n",
    "\n",
    "# Getting Started\n",
    "Our project aims to help consumers find the best deals on a given product based on previous price history and it’s trend for the past 90 days. We will be focusing on Rolex wristwatches, and will be using a variety of classification methods to help forecast pricing and ultimately decide whether or not the price for a current listing is a good or bad deal. The dataset will be created by using Ebay’s API to get data on previously sold listings. \n",
    "\n",
    "## The Data\n",
    "We will be acquiring our data using Ebay's API. This API is easy to use and makes grabbing previous sales easy! However, no dataset is perfect, and we had to go through hefty pre-processing to get the data reaedy. There were three steps to our data collection: Gathering, Cleaning, and Classifying.\n",
    "\n",
    "#### Gathering the data:\n",
    "Like we said earlier, data gathering was completed using Ebay's API. [Here](https://developer.ebay.com/docs) is a link to the documentation if you want to investigate further.\n",
    "\n",
    "\n",
    "Below is the function we used to send a response to Ebay's API. As you can see, we pass in some keywords, sort the results from newest to oldest, ask for 100 entries per page, give it a page number, and a minimum and maximum price for previously sold listings. We use minimum and maximum price as a screen for watch parts and accessories. By setting a mininum price at a level that no Rolex will go under, we save a lot of time in cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(Keywords, pageNum, minPrice, maxPrice, api):\n",
    "    response = api.execute('findCompletedItems', {\n",
    "        'keywords': Keywords,\n",
    "        'sortOrder': 'EndTimeLatest',\n",
    "        'paginationInput': {'entriesPerPage': '100',\n",
    "                            'pageNumber': pageNum},\n",
    "        'itemFilter': [\n",
    "            # {'name': 'Condition', 'value': condition},\n",
    "            {'name': 'SoldItemsOnly', 'value': True},\n",
    "            {'name': 'MinPrice', 'value': minPrice},\n",
    "            {'name': 'MaxPrice', 'value': maxPrice}\n",
    "        ]\n",
    "    }\n",
    "                           )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with any API, you need an API Key. We are sharing an API key, and we will be including ours as a means of demonstration. If you would like to try this project for yourself, please register for your own API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebaysdk.finding import Connection as finding\n",
    "api = finding(appid='EddyNass-Scraper-PRD-651ca6568-7ae32d61', config_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have set the parameters for the API, we can send a request! Let's gather all the items on the first four pages, 400 items in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<item><itemid>254217635900</itemid><title>2005 Unique Rolex Explorer 114270 Black PVD / DLC</title><globalid>EBAY-US</globalid><primarycategory><categoryid>31387</categoryid><categoryname>Wristwatches</categoryname></primarycategory><galleryurl>http://thumbs1.ebaystatic.com/m/mpdOrwj6IVbG2M_ae6sI2cg/140.jpg</galleryurl><viewitemurl>http://www.ebay.com/itm/2005-Unique-Rolex-Explorer-114270-Black-PVD-DLC-/254217635900</viewitemurl><paymentmethod>PayPal</paymentmethod><autopay>false</autopay><postalcode>33132</postalcode><location>Miami,FL,USA</location><country>US</country><shippinginfo><shippingservicecost currencyid=\"USD\">65.0</shippingservicecost><shippingtype>Flat</shippingtype><shiptolocations>Worldwide</shiptolocations><expeditedshipping>true</expeditedshipping><onedayshippingavailable>false</onedayshippingavailable><handlingtime>2</handlingtime></shippinginfo><sellingstatus><currentprice currencyid=\"USD\">4050.0</currentprice><convertedcurrentprice currencyid=\"USD\">4050.0</convertedcurrentprice><bidcount>27</bidcount><sellingstate>EndedWithSales</sellingstate></sellingstatus><listinginfo><bestofferenabled>false</bestofferenabled><buyitnowavailable>false</buyitnowavailable><starttime>2019-05-02T09:53:30.000Z</starttime><endtime>2019-05-09T00:40:02.000Z</endtime><listingtype>Auction</listingtype><gift>false</gift><watchcount>95</watchcount></listinginfo><returnsaccepted>false</returnsaccepted><condition><conditionid>3000</conditionid><conditiondisplayname>Pre-owned</conditiondisplayname></condition><ismultivariationlisting>false</ismultivariationlisting><topratedlisting>false</topratedlisting></item>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "Keywords = \"Rolex Wristwatch\"\n",
    "minPrice = 3000\n",
    "maxPrice = 12000\n",
    "pageNum = 1\n",
    "# Collect all items from ebay on page1 through 4\n",
    "while pageNum <= 4:\n",
    "    soup = BeautifulSoup(response(Keywords, pageNum, minPrice, maxPrice, api).content, 'lxml')\n",
    "    if pageNum == 1:\n",
    "        items = soup.find_all('item')\n",
    "    else:\n",
    "        items += soup.find_all('item')\n",
    "    pageNum += 1\n",
    "items[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ew! The result doesn't look too pretty! We even had to shorten it significantly so it didn't take up the whole notebook! What's happening here is that \"items\" is collecting all of the information that Ebay is sending us, but we can parse it out using BeautifulSoup. To get the necessary "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
